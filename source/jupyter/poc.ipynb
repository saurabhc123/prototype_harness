{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import Placeholders\n",
    "import datetime\n",
    "import random as random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden2 = 50\n",
    "n_classes = 2\n",
    "n_examples = 100\n",
    "support_size = 50\n",
    "\n",
    "def one_hot(vec, vals = n_classes):\n",
    "    n = vec.shape[1]\n",
    "    out = np.zeros((n, vals))\n",
    "    out[np.arange(n), vec] = 1\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_based_labels1(fc_layer_representation, y, c):\n",
    "    indexed_centroids = tf.matmul(y,c)\n",
    "    print(indexed_centroids)\n",
    "    x_distances = tf.reduce_sum(tf.exp(-(tf.square(fc_layer_representation - indexed_centroids))),1)\n",
    "    sum_x_distances = tf.log(tf.reduce_sum(x_distances))\n",
    "    logits = tf.divide(x_distances, sum_x_distances)\n",
    "    return logits\n",
    "\n",
    "def get_cluster_based_labels_revised(fc_layer_representation, y, c):\n",
    "    #centroids_0 = tf.matmul(tf.ones(fc_layer_representation.get_shape()[0]),c[0])\n",
    "    #centroids_1 = tf.matmul(tf.ones(fc_layer_representation.get_shape()[0]),c[1])\n",
    "    centroids_0 = c[0]\n",
    "    centroids_1 = c[1]\n",
    "    centroid_0_differences  = tf.reduce_sum(tf.exp(-(tf.square(fc_layer_representation - centroids_0))),1) #[n x 1]\n",
    "    centroid_1_differences  = tf.reduce_sum(tf.exp(-(tf.square(fc_layer_representation - centroids_1))),1) #[n x 1]\n",
    "    centroid_0_sum = tf.reduce_sum(centroid_0_differences)\n",
    "    centroid_1_sum = tf.reduce_sum(centroid_1_differences)\n",
    "    centroid_0_differences = tf.divide(centroid_0_differences, centroid_0_sum)\n",
    "    centroid_1_differences = tf.divide(centroid_1_differences, centroid_1_sum)\n",
    "    #print(indexed_centroids)\n",
    "    #x_distances = tf.exp(-(tf.square(fc_layer_representation - indexed_centroids)))\n",
    "    #sum_x_distances = tf.log(tf.reduce_sum(x_distances))\n",
    "    #logits = tf.divide(x_distances, sum_x_distances)\n",
    "    #logits = tf.nn.softmax(-tf.stack([centroid_0_differences, centroid_1_differences],1))\n",
    "    logits = tf.stack([centroid_0_differences, centroid_1_differences],1)\n",
    "    logits_sum = tf.reduce_sum(logits,1)\n",
    "    final_logits = logits/tf.reshape(logits_sum, (-1, 1)) \n",
    "    return final_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = tf.random_normal([n_examples, n_hidden2], mean=10.0, stddev=10.0)\n",
    "X_1 = tf.random_normal([n_examples, n_hidden2], mean=30.0, stddev=10.0)\n",
    "X = tf.reshape(tf.stack([X_0, X_1],0),[n_examples*2,n_hidden2])\n",
    "\n",
    "y_0 = tf.reshape(tf.fill([n_examples, n_classes - 1],0),[-1,n_classes - 1])\n",
    "y_1 = tf.reshape(tf.fill([n_examples, n_classes - 1],1),[-1,n_classes - 1])\n",
    "depth = n_classes \n",
    "#y = (tf.one_hot(tf.concat([y_0, y_1],0),depth))\n",
    "y = tf.reshape(tf.one_hot(tf.concat([y_0, y_1],0),n_classes),[n_examples*2,n_classes])\n",
    "\n",
    "C_0 = tf.reduce_mean(X_0[:support_size],0)\n",
    "C_1 = tf.reduce_mean(X_1[:support_size],0)\n",
    "C = tf.stack([C_0,C_1],0)\n",
    "\n",
    "logits = get_cluster_based_labels_revised(X,y,C)\n",
    "labels = tf.argmax(logits, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [200  50]\n",
      "C: [ 2 50]\n",
      "Y: [200   2]\n",
      "Logits Shape: (200,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print(\"X:\",sess.run(tf.shape(X)))\n",
    "    print(\"C:\",sess.run(tf.shape(C)))\n",
    "    print(\"Y:\",sess.run(tf.shape(y)))\n",
    "    logits_ = np.array(sess.run(labels))\n",
    "    print(\"Logits Shape:\",logits_.shape)\n",
    "    print(logits_)\n",
    "    #print(\"Logits:\",logits_[1:3,:])\n",
    "    #print(\"Logits:\",logits_[101:103,:])\n",
    "    #print(logits)\n",
    "    #the_logits = sess.run(logits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
